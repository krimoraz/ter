\documentclass[12pt,a4paper,french]{article}

\input{../../commons.tex.inc}

\title{Lois de probabilité à densité}
\author{\bsc{Jumel}}
\date{avril 2018}

\begin{document}

\maketitle

\bigskip

\section{Lois de probabilités}

Une loi de probabilité est la donnée des probabilités de tous les événements
possibles lors d'une expérience aléatoire. Ainsi, l'expérience aléatoire qui
associe au lancer d'un dé à 6 faces, la valeur de la face obtenue est la loi
de probabilité représentée par le tableau suivant :
\begin{center}
  \begin{tabular}{|*{7}{c|}}\hline
    $X$ & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
    $\p(X = k)$ & $\frac16$ & $\frac16$ & $\frac16$ & $\frac16$ & $\frac16$
                & $\frac16$ \\ \hline
  \end{tabular}
\end{center}
Profitons de cet exemple pour introduire quelques notions.
\begin{definition}
  On dit que $X \colon \Omega \to E$, où $E$ est une partie finie de
  $\Z$, $\N$ entier ou $\R$, est une \emph{variable aléatoire}.\\ On appelle
  \emph{loi de $X$} la probabilité de toutes les valeurs prises par $X$.
\end{definition}

\begin{remarque}
  Le nom est impropre, il faut bien comprendre que $X$ est une fonction de
  $\Omega$, l'univers des possibles, dans un espace de nombre.\\
  En revanche, on ne porte d'intérêt qu'au résultat final mesurable de
  l'expérience aléatoire et non plus à l'événement lui-même. Ainsi, deux
  événements donnant les même résultats seront confondus.
\end{remarque}
Dans le cas de «petits ensembles» $X(\Omega)$ de résultats, on donne souvent
la loi de probabilité sous la forme d'un tableau comme dans l'exemple
ci-dessus.
\begin{definition}
  \begin{itemize}
    \item Lorsque $X(\Omega) \subset \N$ ou $\Z$, on dit que la variable
      aléatoire est discrète.
    \item Lorsque $X(\Omega) \not\subset \N$, on dit que la variable
      aléatoire est continue.
  \end{itemize}
\end{definition}

\subsection{Le cas discret : la loi binomiale}

On étudie ici brièvement la loi binomiale, mais les résultats présentés ici
sont vrais pour les lois discrètes, aux adaptations près. Le cas
d'application de la loi binomiale est le suivant : on répète une même
expérience aléatoire, dont le résultat est succès ou échec, de façon
indépendante. On pourra relire de façon profitable l'activité du début de
l'année sur le sujet.

\begin{definition}
  On dit qu'une telle variable aléatoire suit une loi binomiale
  $\mathcal{B}$ de paramètres $n$ le nombre total de répétitions et $p$ la
  probabilité de succès d'un tirage. On note $X \leadsto \mathcal{B}(n,p)$.
\end{definition}

\begin{proposition}
  Soit $X$ une variable aléatoire suivant une loi binomiale de paramètres $n$
  et $p$. On a \[ \p(X = k) = \binom{n}{k}p^k(1-p)^{n-k} . \]
\end{proposition}
\begin{proof}
  Construire l'arbre «théorique», dénombrer les réalisations positives et
  affecter les probabilités sur les branches. Le nombre $\binom{n}{k}$ étant
  défini précisément comme le nombre de réalisations dans un tel arbre.
\end{proof}

\begin{bclogo}[logo={\Calculatrice*[calcscale=0.3]}]{À la calculatrice}
  \Touche[style=second]
  \Touche[style=function,principal={Vars},second={Distrib}]
  \Touche[style=number,principal=3]
  permet de calculer directement la probabilité, alors que \\
  \Touche[style=second]
  \Touche[style=function,principal={Vars},second={Distrib}]
  \Touche[style=number,principal=4]
  permet de calculer $\p(X ≤ k) = \displaystyle\sum_{l=0}^k \p(X = l)$
\end{bclogo}

\begin{proposition}
  Soit $X$ une variable aléatoire qui suit une loi binomiale de paramètres
  $n$ et $p$. Alors \[ \sum_{k=0}^n \p(X = k) = 1 .\]
\end{proposition}
\begin{proof}
  On applique ici la loi des probabilités totales.
\end{proof}

\begin{question}
  Refaire cette démonstration en utilisant le binôme de Newton.
\end{question}

\begin{definition}
  Soit $X$ une variable aléatoire qui suit une loi binomiale de paramètres
  $n$ et $p$.\\
  L'\emph{espérance mathématique} de $X$, notée $E[X]$, vaut $E[X] =
  \displaystyle\sum_{k= 0}^nk\p(X = k)$
\end{definition}

\begin{proposition}
  Soit $X$ une variable aléatoire qui suit une loi binomiale de paramètres
  $n$ et $p$.\\
  L'espérance mathématiques $E[X]$ vaut $E[X] = np$.
\end{proposition}
\begin{proof}
  Calculons $E[X] = \displaystyle\sum_{k= 0}^nk\p(X = k)$
  \begin{align*}
    E[X] & = \sum_{k= 0}^nk\p(X = k)                        \\
         & = \sum_{k=0}^n k\binom{n}{k}p^k(1-p)^{n-k}       \\
         & = \sum_{k=1}^{n+1} \binom{n}{k-1} p^k(1-p)^{n-k} \\
         & = \sum_{k=0}^n n \binom{n}{k} p^{k+1}(1-p)^{n-k} \\
         & = np \sum_{k=0}^n \p(X = k)                      \\
         & = np
  \end{align*}
\end{proof}

\begin{definition}
  Soit $X$ une variable aléatoire qui suit une loi binomiale de paramètres
  $n$ et $p$.\\
  La variance de $X$, notée $V[X]$, vaut $V[X] = \displaystyle\sum_{k= 0}^n
  k^2 \p(X = k)$.
\end{definition}

\begin{proposition}
  Soit $X$ une variable aléatoire qui suit une loi binomiale de paramètres
  $n$ et $p$.\\
  On a $V[X] ≥ 0$
\end{proposition}
\begin{proof}
  La variance est définie comme une somme de termes positifs.
\end{proof}

\begin{remarque}
  \begin{itemize}
    \item L'espérance est une moyenne pondérée, avec la somme des
      pondérations égale à 1.
    \item La variance pourra s'interpréter comme une moyenne des écarts à la
      moyenne.
    \item Le cas $V[X] = 0$ est très rare et correspond à une loi dans
      laquelle $p \in \{0;1\}$.
  \end{itemize}
\end{remarque}

\begin{proposition}
  Soit $X$ une variable aléatoire qui suit une loi binomiale de paramètres
  $n$ et $p$.\\
  La variance $V[X]$ vaut $V[X] = np(1-p)$.
\end{proposition}
\begin{proof}
  Provisoirement admis.
\end{proof}

\begin{definition}
  On définit l'écart-type $\sigma_X$ par $\sigma_X = \sqrt{V[X]}$.
\end{definition}

\begin{remarque}
  Toutes ces définitions sont valables pour toutes les lois discrètes,
  moyennement un ajustement de la borne supérieure de la somme.\\
  Pour les lois continues, on verra une extension commode de la notion de
  somme.
\end{remarque}

\subsection{Le cas continu : la loi uniforme}

Le modèle utilisé dans cet exemple est celui du tirage aléatoire d'un
nombre réel entre deux réels $a$ et $b$. Il est très similaire au tirage
d'un nombre au hasard entre 0 et 1.

\begin{question}
  Justifier que pour obtenir un nombre au hasard entre $a$ et $b$ est
  équivalent au tirage d'un nombre entre 0 et 1.
\end{question}

\begin{tikzpicture}
  \draw (0,0) -- (5,0) ;
  \draw (1,0) node { $\large [$ };
  \draw (1,-.5) node { $a$ };
  \draw (4,0) node { $\large ]$ };
  \draw (4,-.5) node { $b$ };

  \draw[red] (1.7,0) node { $\large [$ } --(3.3,0) node { $\large ]$ };
  \draw[red] (2.5,-0.5) node { $J$ };
\end{tikzpicture}

On choisit au hasard $x \in \intv{a}{b}$ et on cherche la probabilité
que $x$ appartiennent à $J$, notée $\p(x\in J)$.\\
Supposons que $J = \intv{\frac{p}q}{\frac{p'}q}$, avec $p$, $p'$ et
$q$ convenablement choisis. La probabilité d'appartenir à un tel
intervalle est $\frac{p' - p}{q(b-a)}$. En effet, c'est la probabilité, vue
comme la «mesure» de l'ensemble $J$ divisée par la «mesure» de
$\intv{a}{b}$.\\
Divisons désormais l'intervalle $\intv{a}{b}$ en $n$ intervalle de
longueur $\frac{b-a}n$. Sur tous ces intervalles $J_i = \intv*{a +
i\dfrac{b-a}n}{a + (i+1)\dfrac{b-a}n}$, la probabilité que $x$
appartiennent à un de ces intervalles est constante et vaut $p$ et
la probabilité qu'il appartiennent à la réunion des intervalles vaut 1. \\
Donnons nous $K$, un intervalle arbitrairement choisi. Celui-ci peut-être vu
comme réunion d'intervalles $J_i$ pour un $n$ donné : $K =
\displaystyle\bigcup_{i = l}^m J_i$. Ces intervalles étant deux à deux
disjoints, on pourra donc additionner leurs «mesures» et on obtient donc :
\[ \p(x\in K) =\sum_{i=l}^m \p(x\in J_i) = (m -l)p . \]
Enfin, on trouve que \[ p = \frac1{b - a} . \]

\begin{question}
  \begin{enumerate}
    \item Quelle formule de probabilités est utilisée ici ?
    \item Quel argument permet d'obtenir le dernier résultat ?
%    \item Proposer une interprétation «robuste» du fait que $\sum_{i =
%      a}^b \p(x\in J_i) = 1$ qui permettra une généralisation.
  \end{enumerate}
\end{question}

\begin{bclogo}[logo=\bcattention]{}
  Pour une loi continue, on ne peut pas calculer la probabilité d'obtenir un
  nombre de l'intervalle. On notera plutôt, pour $x \in \intv{a}{b},\ \p(X =
  x) = 0$. En revanche, pour $(x,y) \in \intv{a}{b}^2,\ \p(x ≤ X ≤ y) = \p(X
  \in \intv{x}{y}) = \frac{y - x}{b - a}$.\\
  Ce dernier résultat sera redémontrée d'une autre façon.
\end{bclogo}

\pagebreak

\section{Lois à densité}

\subsection{Généralités}

On va désormais généraliser les résultats précédents. On va admettre
quelques résultats que nous n'exploiterons que dans le cadre de ce cours
et qui nous ameneraient à des développements théoriques très longs.\\
En particulier, on admet que, sous certaines conditions, on peut écrire
$\displaystyle\int_a^{+\infty}f(x)\diff x$ et affirmer qu'il s'agit d'un
nombre réel.
C'est bien souvent un résultat obtenu à partir de
$\displaystyle\lim_{b\to+\infty}\displaystyle\int_a^b f(x) \diff x$.\\
Ceci étant posé, on peut écrire la première définition formelle du
chapitre.

\begin{definition}
  On appelle \emph{densité de probabilité} une fonction $f$ définie et
  continue sur $I$ un intervalle (non nécessairement borné) de $\R$
  telle que son intégrale sur $I$ $\displaystyle\int_{x\in I}f(x) \diff x =
  1$.
\end{definition}

On considère désormais une variable aléatoire $X$ à valeurs dans $I$. On
notera de façon abusive $X \in J$pour indiquer que l'image $X(\omega)$
d'un évenement appartient à l'intervalle (non nécessairement borné) $J$.

\begin{definition}
  On dit que la variable aléatoire \emph{suit la loi de densité $f$}
  lorsque $\p(X\in J) = \displaystyle\int_{J} f(x)\diff{x}$.
\end{definition}

\begin{question}
  Démontrer qu'ainsi, pour $J$ et $K$ deux intervalles de $I$, on a :
  \begin{itemize}
    \item $\p(X\in \overline{J}) = 1 - \p(X\in J)$
    \item $\p(X\in J \cup K) + p(X\in J \cap K) = \p(X\in J) + \p(X\in K)$
  \end{itemize}
  Justifier que, pour une loi à densité, $\p(X \in \{a\}) = \p(X = a) = 0$.
\end{question}

On notera souvent $\p(X\in \{x\in \R | a\leqslant x \leqslant b\})$ par
$\p(a \leqslant X \leqslant b)$ par abus «inverse» de notation.

\begin{proposition}
  Pour toute variable aléatoire $X$ qui suit une loi à densité, on a
  \begin{itemize}
    \item $\p(X = a) = 0$
    \item $\p(X \leqslant a ) = \p(X < a)$
  \end{itemize}
\end{proposition}
\begin{proof}
  Ces affirmations découlent directement des définitions avec les
  intégrales.
\end{proof}

On définit également, par analogie avec les lois dites discrètes,
l'espérance d'une variable aléatoire $X$ dans le cas où celle-ci suit
une loi de densité de probabilité $f$.

\begin{definition}
  Soit $X$ une variable aléatoire continue.
  Sous réserve d'existence de l'intégrale, \emph{l'espérance} de la
  variable aléatoire $X$ est définie par $E(X) = \displaystyle\int_I xf(x)
  \diff x$.
\end{definition}

\subsection{La loi uniforme}

Revenons à notre exemple premier de loi uniforme sur le segment
$\intv{a}{b}$.

\begin{definition}
  La loi de probabilité uniforme a pour densité de probabilité la
  fonction continue défine sur $\intv{a}{b}$ par $f(x) = \frac1{b-a}$
\end{definition}

On vérifie immédiatement que cette fonction définit bien une densité de
probabilité.

\begin{question}
  Calculer $\displaystyle\int_a^b f(x) \diff x$.
\end{question}

On parle de loi de probabilité uniforme car si $J$ et $K$ sont deux
intervalles de même longueur, $\p(X\in J) = \p(X \in K)$

\begin{question}
  Montrer que si $X$ suit une loi uniforme, alors $E(X) = \dfrac{a+b}2$.
\end{question}

Ce résultat est à connaître.

\pagebreak

\section{Loi exponentielle}

\subsection{Définition et espérance}

\begin{definition}
  On appelle \emph{loi exponentielle} de paramètre $\lambda>0$ une loi
  de probabilité dont la densité de probabilité est donnée par
  $f:x\mapsto \lambda e^{-\lambda x}$
\end{definition}

Il faut néamoins vérifier que cette fonction définit bien une densité de
probabilité.

\begin{question}
  Soit $\lambda$ un réél strictement positif.
  \begin{enumerate}
    \item Calculer l'intégrale $\displaystyle\int_0^x \lambda e^{-\lambda t}
      \diff t$ en fonction de $x$ et de $\lambda$.
    \item Donner la limite de la fonction $F:t \mapsto 1 - e^{-\lambda
      t}$ en $+\infty$.
    \item Conclure.
  \end{enumerate}
\end{question}

Le calcul d'une probabilité lorsqu'une variable aléatoire $T$ suit une
loi exponentielle s'obtient généralement par le calcul direct.

\begin{question}
  Soient $a$ et $b$ deux réels tels que $0\leqslant a \leqslant b$.
  Calculer :
  \begin{itemize}
    \item $\p(T \leqslant a) = \displaystyle\int_0^a \lambda e^{-\lambda x}
      \diff x$ ;
    \item $\p(T \geqslant a) = \p(T > a )$
    \item $\p(a \leqslant T \leqslant b)$
  \end{itemize}
\end{question}

On peut s'intéresser à l'espérance d'une telle variable aléatoire.

\begin{proposition}
  L'espérance d'une variable aléatoire $T$ qui suit une loi
  exponentielle de paramètre $\lambda$ est $E(T) = \dfrac1{\lambda}$.
\end{proposition}

\begin{question}
  Soit $\lambda$ un réél strictement positif.
  \begin{enumerate}
    \item Calculer l'intégrale $\displaystyle\int_0^x \lambda te^{-\lambda t} \diff
      t$ en fonction de $x$ et de $\lambda$ (on pourra utiliser une
        intégration par parties ou poser $f:t\mapsto \lambda
        te^{-\lambda t}$ et étudier $\lambda f + f'$.)
    \item Donner la limite de la primitive trouvée ci-dessus en
      $+\infty$.
    \item Conclure.
  \end{enumerate}
\end{question}

\subsection{Loi de vieillissement « sans mémoire»}

Dans cette partie, $t$ et $h$ sont deux nombres réels positifs et on
note $\p(A | B) = \p_B(A)$ la probabilité de l'événement $A$ sachant que
l'événement $B$ est réalisé.\\
On rappelle également que $\p(A | B) = \frac{\p(A\cap B)}{\p(B)}$.

\begin{definition}
  On dit qu'un processus aléatoire est «sans mémoire» lorsque la
  probabilité qu'il tombe en panne au bout de $t+h$ sachant qu'il a
  fonction $t$ heures est identique à la probabilité qu'il cesse de
  fonctionner au bout de $h$ heures. Mathématiquement, si $T$ est la
  variable aléatoire qui à un composant associe sa durée de vie en
  heures, alors $\p(T > t+h | T > t) = \p(T > h)$
\end{definition}

Une autre formulation est de dire que la probabilité $\p(T > t+h | T >
t)$ ne dépend pas de $t$.

Ce modèle est particulièrement vrai dans le cadre de la modélisation des
composants électroniques non chimiques qui entre pour une partie non
négligeable des produits fabriqués aujourd'hui. Ce modèle est également
utilisé pour décrire un taux de panne constant sur des systèmes
complexes.

Ce modèle n'est en revanche pas valide pour les pièces présentant une
usure mécanique qui est généralement quantifiable et donc ne fait pas
appel à des méthodes probabbilistes.

\begin{proposition}
  La loi exponnentielle est une loi «sans vieillissement».
\end{proposition}
\begin{proof}
  \begin{question}
    Soit $T$ une variable aléatoire qui suit une loi exponnentielle de
    paramètre $\lambda$.
    \begin{enumerate}
      \item Exprimer $\p(T > t+h | T > t)$ en fonction de $\p(T > t+h)$
        et de $\p(T > t)$.
      \item Exprimer $\p(T > t+h)$ et $\p(T > t)$ avec des
        exponnentielles.
      \item Interpréter $e^{-\lambda h}$ comme une probabilité.
      \item Conclure.
    \end{enumerate}
  \end{question}
\end{proof}

On admet que la réciproque est également vraie et que les variables
aléatoires qui suivent des lois exponnentielles sont les seules
variables aléatoires «sans vieillissement». En fait, cette démonstratio
n'est possible que si on dispose d'une théorie des équations
différentielles qui permet de réellement montrer l'existence et
l'unicité de la fonction exponnentielle et qui a permis de construire la
loi exponnentielle à partir des lois «sans usure».

\pagebreak

\section{Loi normale}

Dans cette partie, on parle indiférement de la loi de Laplace-Gauss ou
de la loi normale pour désigner la même densité de probabilité.

\subsection{Le cas «simple» : la loi normale centrée-réduite}

L'appellation de centrée-réduite sera justifiée par la suite.

\begin{definition}
  La fonction $\varphi : x\mapsto \frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}$
  s'appelle \emph{densité de probabilité de la loi normale}.
\end{definition}

On dit aussi loi de Laplace-Gauss du nom des premiers mathématiciens à
l'avoir étudié.

\begin{proposition}[admise]
  \[ \displaystyle\int_{-\infty}^{+\infty} e^{-\frac{x^2}2} = \sqrt{2\pi} \]
\end{proposition}

Ce résultat général est dur à obtenir, mais il nous assure que la
fonction $\varphi$ définie ci-dessus est bien une densité de
probabilité.

\begin{question}
  Justifier cette affirmation.
\end{question}

\begin{definition}
  On dit qu'une variable aléatoire $Z$ suit la loi normale
  centrée-réduite lorsque $\p(a\leqslant Z \leqslant b) =
  \displaystyle\int_a^b \varphi(x)\diff x$. On note $Z \leadsto
  \mathcal{N}(0,1)$.
\end{definition}

\begin{remarque} La notation $\mathcal{N}(0,1)$ sera expliquée
  rapidement par la suite. Ces deux valeurs 0 et 1 sont à connaître pour
  la loi centrée-réduite : elles permettent le calcul effectif d'une
  probabilité avec la calculatrice.
\end{remarque}

Il est aussi parfois commode d'envisager la probabilité pour $Z$ d'être
entre $a$ et $b$ comme l'aire sous une courbe. Cette méthode avait un
grand avantage de simplification avant l'arrivée des calculatrices. En
effet, la primitive $\Phi$ de $\varphi$ ne pouvant s'exprimer avec des
fonctions usuelles, les valeurs de $\Phi$ étaient tabulées sur la
demi-droite des $x$ positifs.

\begin{proposition}
  $\p(a \leqslant X \leqslant b) = \Phi(b) - \Phi(a)$
\end{proposition}
\begin{proof}
  $\Phi$ est, par définition, une primitive de $\varphi$.
\end{proof}

Les $x$ positifs suffisent, en vertu de cette propriété :

\begin{proposition}
  Pour tout $x$ réel, $\Phi(-x) = 1 - \Phi(x)$
\end{proposition}
\begin{proof}
  Par symétrie de $\varphi$ et en utilisant le fait que le poids total
  est de 1.
\end{proof}

Cependant, ce résultat peut servir lors de certaines démonstrations.

Calculons l'espérance d'une variable aléatoire suivant une telle loi.

\begin{question}
  Soit $a$ un nombre réel.
  \begin{enumerate}
    \item Calculer $\displaystyle\int_0^a x\varphi(x) \diff x$.
    \item En déduire $\lim_{a\to+\infty} \displaystyle\int_0^a x\varphi(x)
      \diff x$.
    \item Conclure sur l'espérance $E(Z)$.
  \end{enumerate}
\end{question}

\begin{definition}[Variance]
  Soit $Z$ une variable aléatoire qui suit une loi normale
  centrée-réduite. On appelle \emph{variance} et on note $\sigma^2$ le
  nombre défini par $\sigma^2 = \displaystyle\int_{-\infty}^{+\infty}
  x^2\varphi(x) \diff x$.
\end{definition}

\begin{proposition}
  La variance $\sigma^2$ d'une variable qui suit la loi normale
  centrée-réduite est $\sigma^2 = 1$
\end{proposition}
\begin{proof}
  questions 82 et 83 p 432
\end{proof}

\begin{proposition}[admise]
  $\sigma^2 = E((X - E(X))^2)$
\end{proposition}

\begin{question}
  Montrer que cette dernière proposition conduit à la définition
  proposée de la variance. Interpréter la variance en terme de
  moyenne.
\end{question}

Dans la littérature, on note souvent la moyenne $\mu$ et la variance
$\sigma^2$.

\pagebreak

\subsection{Le cas général}

On a vu, dans la partie précédente, un cas particulier de loi normale
lorsque les paramètres $\mu$ et $\sigma^2$ valent respectivement 0 et 1,
ce qui n'est pas toujours le cas.

On peut aisément généraliser et considérer une variable aléatoire $X$
qui suit une loi normale d'espérance $\mu$ quelconque et $\sigma^2 > 0$.

\begin{proposition}
  Si $X \leadsto \mathcal{N}(\mu,\sigma^2)$, alors $Z = \frac{ X -
  \mu}{\sigma^2}$ suit une loi normale centrée-réduite.
\end{proposition}

\begin{question}
  On considère une variable aléatoire $X$ qui suit une loi normale de
  paramètres $\mu$ et $\sigma^2$.
  \begin{enumerate}
    \item Donner l'expression de $X$ en fonction de $Z$ lorsque $Z$ suit
      la loi normale centrée-réduite.
    \item En déduire l'expression de la densité de probabilité de $X$.
  \end{enumerate}
\end{question}

En règle général, le calcul des valeurs de la loi normale se fait
désormais à la calculatrice.

\begin{bclogo}[logo={\Calculatrice*[calcscale=0.3]}]{À la caluclatrice}
  \Touche[style=second]
  \Touche[style=function,principal={Vars},second={Distrib}]
  \Touche[style=number,principal=3]
  permet de calculer directement la probabilité, alors que \\
  \Touche[style=second]
  \Touche[style=function,principal={Vars},second={Distrib}]
  \Touche[style=number,principal=4]
  permet de calculer $\p(X ≤ k) = \displaystyle\sum_{l=0}^k \p(X = l)$
\end{bclogo}

\section{Applications et autres exemples}

\subsection{Quelques valeurs particulières à connaître}

Avant de se lancer dans le calcul à proprement parler, démontrons une
première propriété.

\begin{proposition}
  Soit $\alpha \in \intv[o]{0}{1}$ et $X$ une variable aléatoire qui suit
  la loi normale centrée-réduite. Il existe un unique réel positif
  $u_{\alpha}$ tel que $\p(-u_{\alpha} \leqslant X \leqslant u_{\alpha}) = 1
  - \alpha$.
\end{proposition}

\begin{question}
  On se donne $\alpha \in \intv[o]{0}{1}$.
  \begin{enumerate}
    \item Exprimer $\Phi(x)$ en fonction de $\alpha$ où $\Phi$ est la
      primitive (aire sous la courbe de la densité de densité de
      probabilité) qui vaut $\frac12$ en 0.
    \item Vérifier que $\Phi$ respecte les hypothèses d'un théorème
      important du cours de Terminale.
    \item Conclure.
  \end{enumerate}
\end{question}

En particulier, il faut connaître : $u_{\np{0.05}} = \np{1.96}$ et
$u_{\np{0.01}} = \np{2.58}$. De façon équivalente, on obtient $\p(-1,96
\leqslant X \leqslant 1,96) \approx 0,95$ et $\p(-2,58 \leqslant X
\leqslant 2,58) \approx 0,99$.

Il est intéressant de noter que ce sont des cas particuliers de points
plus généraux qu'on peut exprimer ainsi :
\begin{itemize}
  \item $\p(\mu - \sigma \leqslant X \leqslant \mu + \sigma) \approx
    0,63$
  \item $\p(\mu - 2\sigma \leqslant X \leqslant \mu + 2\sigma) \approx
    0,95$
  \item $\p(\mu - 3\sigma \leqslant X \leqslant \mu + 3\sigma) \approx
    0,99$
\end{itemize}

\pagebreak

\subsection{Approximation d'une loi binomiale par une loi normale}

On a vu dans une activité que la loi binomiale pouvait, sous certaines
hypothèses, permettre de modéliser un nouveau type de loi, la loi de
Poisson. On conservait cependant un invariant : l'espérance des deux
lois restait la même.

On peut de même approcher, sous certaines conditions la loi binomiale
par une loi normale, c'est le théorème de Moivre-Laplace.

\begin{theoreme}[Admis]
  Soit $X$ une variable aléatoire qui suit une loi binomiale
  $\mathcal{B}(n,p)$ et $Z = \frac{X - E(X)}{\sigma(X)} = \frac{X -
  np}{\sqrt{np(1-p)}}$.

  Alors $\lim_{n\to+\infty} P(a \leqslant Z \leqslant b) =
  \displaystyle\int_a^b \varphi(x) \diff x$.
\end{theoreme}

\begin{remarque}
  Pour $n \leqslant 30$ ou $np$ ou $n(1-p) \leqslant 5$, cette
  approximation n'est pas valide.
\end{remarque}

\end{document}
